p.587_chapter20

20장
딥러닝 튜닝

딥러닝을 이용하면 분류 또는 회귀 모델을 손쉽게 만들수있지만, 네트워크를 구성할때
사람이 파라미터를 조정해야 하는데
이를 하이퍼파라미터 라고 한다.

은닉층 수 및 은닉층 유닛 수를 많게 하면 입력층에 가까운 가중치를 적절하게 갱신하기가 어렵고,
학습이 좀처럼 진행되지 않는다.
중요성이 낮은 특징량을 추출해버려 과학습하기 쉽다.

드롭아웃

과학습을 방지하여 모델의 정확도를 높이는 방법 중 하나이다.
유닛의 일부가 무작위로 제거된다.
결과적으로 학습 데이터의 과학습을 예방 할수 있다.

활성화 함수

주로 전결합층 뒤에 작용하는 함수로, 뉴런의 발화에 해당한다.
전결합층에서는 입력을 선형변환한 것을 출력하지만,
활성화 함수를 이용함으로써 비선형성을 갖게된다.

종류
: 시그모이드 함수
: ReLU함수

손실함수

학습시 모델의 출력과 지도 데이터의 차이를 평가하는 함수를 말한다.
제곱오차, 교차 엔트로피 오차 등이 사용되고,
이 손실함수를 최소화하도록 오차역전파법으로 각 층의 가중치가 갱신된다.

제곱오차

최소제곱으로 통계학 등 다양한 분야에서 사용된다.
연속값 평가가 뛰어나므로 주로 회귀 모델의 오차 함수로 사용한다.

교차 엔트로피 오차

이항 분류의 평가에 특화되있다.
분류 모델의 함수로 사용된다.

최적화 함수

가중치 갱신은 오차 함수를 각 가중치로 미분한 값을 바탕으로 갱신해야 할 방향과 
어느 정도로 갱신할지 결정하는 함수이다.

미분에 의헤 구한 값을  학습 속도, epoch수, 과거의 가중치 갱신량 등을 근거로 어떻게 가중치에 반영할지 정한다.

미니배치 학습

모델의 학습을 실시할 댸 한 번에 모델에 전달하는 입력 데이터 수를 바꿀수있다.
한 번에 전달하는 데이터의 수를 배치 사이즈 라고 한다.
가중치 갱신은 구해진 기울기의 평균으로 한 번만 실시한다.

.배치 크기를 1로 하는 방식 : 온라인 학습
    "   "       전체 데이터 수로 지정 : 배치학습(경사하강법)
이들의 중간 : 미니배치 학습

반복학습

모델의 정확도를 높이기 위해 동일한 훈련 데이터를 사용하여 여러번 학습시키는 것


